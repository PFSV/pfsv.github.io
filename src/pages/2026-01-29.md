korail report generation
* 코레일 온프레미스에 적용 완료 
- 백엔드랑 붙는거 해야함(내일 내일모레 개발된다함)  -> 고정값으로 하책임이 테스트 할 수 있게 해준다고 함
    - reference_data_pdf : {"title":"text","title2","text2", ...} # key-value style
        text_data_txt : [text1, text2, ...] # array
        report_info : {
            id : 1,
            detail_list : [
                {"id":1,
                "report_id": text,
                "category"},
                ...
            ]
        }
    -> 여차저차 했는데 지금 스테이트부터 길이 관련까지 문제가 많음
	=> [이사님] 값이 가변적으로 바뀌어야하고, concaternate로 내용 추가해서 전체 포맷 설정 후 제공
	=> 톤&매너, 강조 포인트 등의 예시 Instruction은 선 작성 후 검토( 클릭 -> 이후 매핑 테이블 기반 프롬프트로 바뀌게) =>  페르소나 적용하는거 추가해야함 => ppt에 있는 내용으로 우선 추가해놓기
	

- response는 answer: str, SSE 방식으로 해서 classify, generate, output 단계에서 상태값 전달 (langraph SSE 변환 -> requery 코드 참조)

* 사규내규 검색시스템(Airail)
 - 토피컬 가드레일 부착 - 25% 중 17% 약 2%정도의 non-related question 을 오답이 아니라 Nan으로 바꾸려고 함 
 - unrelated question : 0, 보통 질문 :1 로 topical guardrail 설정 
    ->  unrelated question은 korail 서버에 있음, 코드 넣어서 테스트 해보기
    -> 김상진 이사님께 unrelated questions, normal questions 세트 좀 달라고 하고, 페르소나 관련 이야기도 ㄱ
* vllm 2,3 GPU cache 안 쓰고있음 -> context length 이슈로 보임 (vram not enough)
-> max context length 13k -> 7k로 내림, gpu cache usage 올라갔으나 2%대, generation TPS 200대 


* Agentic RAG pytorch 자료

-> 기존 래그랑 비교 

| 특징 | 기존 RAG (Typical RAG) | Agentic RAG (This Repo) |
|------|------------------------|--------------------------|
| 처리 방식 | 단방향 선형 파이프라인 (검색 → 생성) | 순환형 그래프 워크플로우 (LangGraph) |
| 질의 처리 | 단일 스레드 처리 | Multi-Agent Map-Reduce (병렬 처리) |
| 검색 단위 | 문맥과 정밀도가 상충됨 (Trade-off) | 계층적 인덱싱 (정밀도 + 풍부한 문맥) |
| 대화 맥락 | 이전 대화 기억 못 함 (Stateless) | 대화 메모리 (Conversation Memory) 탑재 |
| 불명확한 질문 | 엉뚱한 답변을 하거나 답변 거부 | 사용자에게 되물어 명확화 (Query Clarification) |
| 유연성 | 커스터마이징이 어려움 | 모듈형 아키텍처 (컴포넌트 교체 용이) |

-> 특별한 포인트

두 가지 학습 경로: 입문자를 위한 '대화형 노트북(Interactive Notebook)'과 개발자를 위한 '모듈형 프로젝트(Modular Project)' 구조를 모두 제공합니다.

계층적 인덱싱 (Hierarchical Indexing): 작은 청크로 정밀하게 검색하고, 큰 청크로 문맥을 보강하여 정확도와 맥락을 동시에 확보했습니다. => parent & child chunking

대화 메모리 (Conversation Memory): 이전 대화 내용을 유지하여 사람과 대화하듯 자연스러운 상호작용이 가능합니다.

Human-in-the-loop: 질문이 불명확할 경우 AI가 사용자에게 역으로 질문하여 의도를 명확히 합니다.

Multi-Agent Map-Reduce: 복잡한 질문을 여러 하위 질문으로 분해하고, 여러 에이전트가 병렬로 처리하여 답변을 완성합니다.

모듈형 아키텍처: 특정 컴포넌트(LLM, DB 등)를 원하대로 쉽게 교체할 수 있는 유연한 구조입니다.

LLM 중립성 (Provider-agnostic): Ollama(로컬), OpenAI, Gemini, Claude 등 원하는 모델을 설정 한 줄로 교체하여 사용할 수 있습니다.

완전한 UI 제공: 문서 업로드 및 관리 기능이 포함된 완성형 Gradio 웹 인터페이스를 제공합니다.

* 트위터 추천 알고리즘 업데이트 및 공개 -> 비슷한 걸 해보자 !

https://github.com/xai-org/x-algorithm?utm_source=pytorchkr&ref=pytorchkr

https://discuss.pytorch.kr/t/x-algorithm-x-twitter/8785